# Vector Embeddings Databases
The core idea behind retrieval augmented generation (RAG) systems is leveraging external information to enhance the capabilities of a large language model (LLM). Typically, this involves an initial retriever component which finds relevant context passages from a vector database. These passages are encoded into vector representations and compared via cosine similarity to the user’s query, also encoded as a vector. The most similar passages are retrieved and fed into the LLM to inform its response generation.

VECTOR database is a type of database that stores data as high-dimensional vectors, which are mathematical representations of raw data. The vectors are usually generated by applying some kind of transformation or embedding function to the raw data, such as text, images, audio, video, and others. Each vector has a certain number of dimensions, which can range from tens to thousands, depending on the complexity and granularity of the data.
Embeddings are dense vector representations of entities and relationships that encode semantic meaning. Each entity or relation is mapped to a point in high-dimensional continuous vector space. Embeddings enable efficient vector similarity computations to generalize patterns.

Vector space models are incredibly useful tools in natural language processing. By representing linguistic items as vectors in a high-dimensional space, these models can capture semantic similarity — words or sentences with similar meanings tend to be closer together in the vector space. For example, the embeddings for “Paris” and “France” will be closer than “Paris” and “China”, reflecting their real-world connection.

Fast and accurate similarity search and retrieval. Vector database can find the most similar or relevant data based on their vector distance or similarity, which is a core functionality for many applications that involve natural language processing, computer vision, recommendation systems, etc.

As part of the exploration work for understanding the inner-workings of Vector Emmeddings, see the companion [**sample code examples here**](/Vector)
